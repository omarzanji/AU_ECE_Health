
\documentclass[12pt]{report}
\usepackage{aums}       % For Master's papers
% \usepackage{auphd}     % For Ph.D.
%\usepackage{auhonors}  % For honors college
\usepackage{ulem}       % underlining on style-page; see \normalem below
\usepackage{url}
\usepackage{tikz}
\usepackage{pgf}
\usepackage[intoc]{nomencl}
\usepackage{graphicx}
\usepackage{hyperref}
\graphicspath{ {./images/} }
\renewcommand{\nomname}{List of Abbreviations}   	       
\makenomenclature 

%% don't forget to run:   makeindex ausample.nlo -s nomencl.ist -o ausample.nls
%% Also, if 
% May want theorems numbered by chapter
% \newtheorem{theorem}{Theorem}[chapter]

% Put the title, author, and date in. 
\title{Sleep Stage Prediction via Deep Learning
using Actigraphy Data to Detect Disorders
by Modeling Sleep}
\author{Omar Barazanji} 
\date{May 10, 2022} %date of graduation
\copyrightyear{2022} %copyright year

\keywords{Deep Learning, Time-Series Forecasting, Health, Sleep}

% Put the Thesis Adviser here. 
\adviser{SueAnne Griffith}

% Put the committee here (including the adviser), one \professor for each. 
% The advisor must be first, and the dean of the graduate school must be last.
% \professor{Thaddeus Roppel, Chair, Associate Professor of Electrical and Computer Engineering}

% \professor{Prathima Agrawal, Ginn Distinguished Professor of Electrical and Computer Engineering}

\professor{SueAnne Griffith, Professor of Electrical and Computer Engineering}

\begin{document}

\begin{romanpages}      % roman-numbered pages 

\TitlePage 

\begin{abstract} 
  In this study, we use datasets \cite{zhang}\cite{bessone} on regular sleep activity to train a model that can accurately predict and label sleep/wake from actigraphy. We created a
  custom dataset on patients with known disorders that affect sleep, through a mix of
  public datasets and sleep studies, to add labels for each person’s known disorder.
  With the disorder labels on the actigraphy data, our trained model will be able to
  predict if a person is healthy or shows behaviors similar to a known disorder.
\end{abstract}

\begin{acknowledgments}
  The National Sleep Research Resource was supported by the U.S. National Institutes of Health, National Heart Lung and Blood Institute (R24 HL114473, 75N92019R002).
\end{acknowledgments}

\tableofcontents
\listoffigures
% \listoftables

\printnomenclature[0.5in] %used for the List of Abbreviations
\end{romanpages}        % All done with roman-numbered pages


\normalem       % Make italics the default for \em


\chapter{Introduction}

Sleep is one of the most important functions in the human body. It is also very predictable and has expected patterns that we can model. Sleep activity can be either quiet, non-rapid eye movement (NREM) or active, rapid eye movement (REM) sleep. To capture sleep data, high sensitivity accelerometers can be attached to the wrist and other parts of the body during sleep to capture the predictable movements during NREM/REM. This data is referred to as actigraphy. There are existing models that can automatically label actigraphy data, but there is a lack of models that can accurately predict disorders that affect sleep. 

\section{Objective}

In this study, we used datasets on regular sleep activity to train a model that can accurately predict and label sleep/wake from actigraphy. We then will create a custom dataset on patients with known disorders that affect sleep. Through a mix of public datasets and sleep studies, we can add labels for each person's known disorder. With the disorder labels on the actigraphy data, our trained model will be able to predict if a person might have certain disorders or not, such as Sleep Apnea.

\pagebreak

\section{Datasets}

We used various datasets in this study and will be referenced throughout the paper. The first dataset is Sleep Actigraphy from the Urban Poor in India, and it contains 3-axis accelerometer data from 30 participants. Data is labeled with sleep status, either a 1 or a 0 for asleep or awake, respectively. The other dataset comes from Sleep as Android Watch Actigraphy. This dataset contains labels for sleep stages as well as lux (light in lumens), snoring, bpm, and more. Data is collected from a compatible Wear OS device during sleep and is converted into a single actigraphy curve for sleep stage prediction.

\subsection{Sleep Actigraphy from the Urban Poor in India}
Need to add...

\subsection{Sleep as Android Watch Actigraphy}
Need to add...

\pagebreak

\begin{figure}
  \begin{center}
    \includegraphics[width=1\linewidth]{model_test_subject5005_day7}
    \caption{Sleep Actigraphy from the Urban Poor in India\cite{zhang}\cite{bessone}}
    \label{urban-poor}
  \end{center}
\end{figure}

\begin{figure}
  \begin{center}
    \includegraphics[width=1\linewidth]{REM_NREM_labels}
    \caption{Sleep as Android Watch Actigraphy}
    \label{sleep-android}
  \end{center}
\end{figure}

\chapter{Methods}

We present various methods for sleep/wake prediction, sleep stage prediction, and disorder prediction. We explore popular known methods using XGBoost, SVM, and RNN model architectures. In this paper we propose a new method for sleep-stage classification and sleep/wake classification. Our baseline method will be the vanilla LSTM and we will compare this against our newly proposed methods using the Transformer architecture and another model using a Bidirectional LSTM. 

\section{Sleep/Wake Prediction}
Recurrent Neural Networks (RNNs) are a special type of neural network that are designed to process long sequences of data and predict how a series of data should continue per time step. The Long Short-Term Memory (LSTM) network is a refined version of the vanilla RNN that can "forget" useless information in training data. This prevents the network from overfitting, which is a big problem in the vanilla RNN. Looking at sleep actigraphy data as a time series problem makes the prediction of any label from the training data quite simple. For example, figure \ref{urban-poor} above shows the x, y, and z activity data from the accelerometers on a participant's wrist, and the sleep status (1=asleep, 0=awake) shows when the person is asleep or awake in time with the accelerometer. We can sub-sample all 4 labels together with a window size of T, usually around T=30, and predict sleep status or anyother variable that was recorded along with the accelerometer per time step. 

\begin{figure}
  \begin{center}
    \includegraphics[width=0.7\linewidth]{sleep_status_LSTM_model}
    \caption{LSTM Model with 256 units for Sleep/Wake Prediction}
    \label{lstm-architecture}
  \end{center}
\end{figure}

\section{Sleep Stage Prediction}
To classify sleep stages as multiple labels during sleep from actigraphy data, we will need to use a multi-variate LSTM that can output more than one label per time step. To do this we will update our vanilla LSTM model's output Y from figure \ref{lstm-architecture} to have a dimension equal to the number of desired sleep stage labels. For our dataset shown in \ref{sleep-android}, we can predict light, deep, and REM sleep stages. We can also add sleep/wake from the Sleep as Android dataset to have a total of 4 output labels per timestep. 

\section{Disorder Prediction}
Need to add...

\chapter{Results}

Results for sleep/wake predcition using the LSTM network with 256 units can be seen below in figures \ref{lstm-loss} and \ref{lstm-accuracy}. The model performs at 92 percent accuracy with 256 units and 15 training epochs. 

\section{Sleep/Wake Results}
Need to add...

\subsection{XGBoost}
Need to add...

\subsection{SVM}
Need to add...

\subsection{LSTM}
Need to add...

\subsection{Transformer}
Need to add...

\section{Sleep Stage Results}
Need to add...

\subsection{XGBoost}
Need to add...

\subsection{SVM}
Need to add...

\subsection{LSTM}
Need to add...

\subsection{Transformer}
Need to add...

\begin{figure}
  \begin{center}
    \includegraphics[width=0.9\linewidth]{param_sweep_loss}
    \caption{Loss on Model with 256 units for Sleep/Wake Prediction during Training}
    \label{lstm-loss}
  \end{center}
\end{figure}

\begin{figure}
  \begin{center}
    \includegraphics[width=0.9\linewidth]{param_sweep_accuracy}
    \caption{Accuracy on Model with 256 units for Sleep/Wake Prediction during Training}
    \label{lstm-accuracy}
  \end{center}
\end{figure}

\chapter{Conclusion}
Need to add...

\section{Discussion}
Need to add...

\section{Conclusion}
Need to add...

\begin{thebibliography}{99}
\newcommand{\AmS}{$${\protect\the\textfont2 A}\kern-.1667em\lower
         .5ex\hbox{\protect\the\textfont2 M}\kern
         -.125em{\protect\the\textfont2 S}}

\bibitem{zhang} Zhang GQ, Cui L, Mueller R, Tao S, Kim M, Rueschman M, Mariani S, Mobley D, Redline S. The National Sleep Research Resource: towards a sleep data commons. J Am Med Inform Assoc. 2018 Oct 1;25(10):1351-1358. doi: 10.1093/jamia/ocy064. PMID: 29860441; PMCID: PMC6188513.

\bibitem{bessone} 
Bessone P, Rao G, Schilbach F, Schofield H, Toma M. The Economic Consequences of Increasing Sleep Among the Urban Poor. Q J Econ. 2021 Apr 8;136(3):1887-1941. doi: 10.1093/qje/qjab013. PMID: 34220361; PMCID: PMC8242594.

\bibitem{sano}
A. Sano, W. Chen, D. Lopez-Martinez, S. Taylor and R. W. Picard, "Multimodal Ambulatory Sleep Detection Using LSTM Recurrent Neural Networks," in IEEE Journal of Biomedical and Health Informatics, vol. 23, no. 4, pp. 1607-1617, July 2019, doi:10.1109/JBHI.2018.2867619.

\bibitem{sathyanarayana} 
Sathyanarayana, Aartietal. “Sleep Quality Prediction From Wearable Data Using Deep Learning.” JMIR mHealth and uHealth vol. 4, 4e125.4Nov.2016, doi:10.2196/mhealth.6562.

\end{thebibliography}



\appendix
\chapter*{Appendices\addcontentsline{toc}{chapter}{Appendices}}

\chapter{Source Code}

\begin{singlespace}
Code link
\end{singlespace}

\end{document}